{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bcd88fb5-6a0f-4c4b-81fd-34be59ea7903",
   "metadata": {},
   "source": [
    "模型下载链接：https://hf-mirror.com/BlinkDL/rwkv-4-pile-430m/resolve/main/RWKV-4-Pile-430M-20220808-8066.pth?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b78b7ef-acc6-46cf-88c2-f90a2835e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM\n",
    "########################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=200)\n",
    "import types, torch\n",
    "from torch.nn import functional as F\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deacc22b-2896-4b77-b595-3284b0c13544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"20B_tokenizer.json\")\n",
    "\n",
    "args = types.SimpleNamespace()\n",
    "args.MODEL_NAME = '/data1/ckw/RWKV-4-Pile-430M-20220808-8066'\n",
    "args.n_layer = 24\n",
    "args.n_embd = 1024\n",
    "\n",
    "context = \"\\nDataWhalechina is an organization founded at Shanghai Jiao Tong University that helps learners learn artificial intelligence.\"\n",
    "NUM_TRIALS = 3\n",
    "LENGTH_PER_TRIAL = 100\n",
    "TEMPERATURE = 1.0\n",
    "TOP_P = 0.85\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1b2e2b-9f0d-4db3-b9d9-d43e3e2537ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RWKV_RNN(torch.jit.ScriptModule):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.eval() # set torch to inference mode\n",
    "        \n",
    "        w = torch.load(args.MODEL_NAME + '.pth', map_location='cpu')\n",
    "        for k in w.keys():\n",
    "            if      '.time_' in k: w[k] = w[k].squeeze()\n",
    "            if '.time_decay' in k: w[k] = -torch.exp(w[k].float()) # the real time decay is like e^{-e^x}\n",
    "            else: w[k] = w[k].float() # convert to f32 type\n",
    "        \n",
    "        self.w = types.SimpleNamespace() # set self.w from w\n",
    "        self.w.blocks = {}\n",
    "        for k in w.keys(): # example: \"blocks.0.att.time_first\" => self.w.blocks[0].att.time_first\n",
    "            parts = k.split('.')\n",
    "            last = parts.pop()\n",
    "            here = self.w\n",
    "            for p in parts:\n",
    "                if p.isdigit():\n",
    "                    p = int(p)\n",
    "                    if p not in here: here[p] = types.SimpleNamespace()\n",
    "                    here = here[p]\n",
    "                else:\n",
    "                    if not hasattr(here, p): setattr(here, p, types.SimpleNamespace())\n",
    "                    here = getattr(here, p)\n",
    "            setattr(here, last, w[k])\n",
    "\n",
    "    def layer_norm(self, x, w):\n",
    "        return F.layer_norm(x, (self.args.n_embd,), weight=w.weight, bias=w.bias)\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def channel_mixing(self, x, state, i:int, time_mix_k, time_mix_r, kw, vw, rw):\n",
    "        xk = x * time_mix_k + state[5*i+0] * (1 - time_mix_k)\n",
    "        xr = x * time_mix_r + state[5*i+0] * (1 - time_mix_r)\n",
    "        state[5*i+0] = x\n",
    "        r = torch.sigmoid(rw @ xr)\n",
    "        k = torch.square(torch.relu(kw @ xk)) # square relu, primer paper\n",
    "        return r * (vw @ k)\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def time_mixing(self, x, state, i:int, time_mix_k, time_mix_v, time_mix_r, time_first, time_decay, kw, vw, rw, ow):\n",
    "        xk = x * time_mix_k + state[5*i+1] * (1 - time_mix_k)\n",
    "        xv = x * time_mix_v + state[5*i+1] * (1 - time_mix_v)\n",
    "        xr = x * time_mix_r + state[5*i+1] * (1 - time_mix_r)\n",
    "        state[5*i+1] = x\n",
    "        r = torch.sigmoid(rw @ xr)\n",
    "        k = kw @ xk\n",
    "        v = vw @ xv\n",
    "        \n",
    "        aa = state[5*i+2]\n",
    "        bb = state[5*i+3]\n",
    "        pp = state[5*i+4]\n",
    "        ww = time_first + k\n",
    "        qq = torch.maximum(pp, ww)\n",
    "        e1 = torch.exp(pp - qq)\n",
    "        e2 = torch.exp(ww - qq)\n",
    "        a = e1 * aa + e2 * v\n",
    "        b = e1 * bb + e2\n",
    "        wkv = a / b\n",
    "        ww = pp + time_decay\n",
    "        qq = torch.maximum(ww, k)\n",
    "        e1 = torch.exp(ww - qq)\n",
    "        e2 = torch.exp(k - qq)\n",
    "        state[5*i+2] = e1 * aa + e2 * v\n",
    "        state[5*i+3] = e1 * bb + e2\n",
    "        state[5*i+4] = qq\n",
    "        return ow @ (r * wkv)\n",
    "\n",
    "    def forward(self, token, state):\n",
    "        with torch.no_grad():\n",
    "            if state == None:\n",
    "                state = torch.zeros(self.args.n_layer * 5, self.args.n_embd)\n",
    "                for i in range(self.args.n_layer): state[5*i+4] = -1e30 # -infinity\n",
    "            \n",
    "            x = self.w.emb.weight[token]\n",
    "            x = self.layer_norm(x, self.w.blocks[0].ln0)\n",
    "            for i in range(self.args.n_layer):\n",
    "                att = self.w.blocks[i].att\n",
    "                x = x + self.time_mixing(self.layer_norm(x, self.w.blocks[i].ln1), state, i, \n",
    "                    att.time_mix_k, att.time_mix_v, att.time_mix_r, att.time_first, att.time_decay, \n",
    "                    att.key.weight, att.value.weight, att.receptance.weight, att.output.weight)\n",
    "                ffn = self.w.blocks[i].ffn\n",
    "                x = x + self.channel_mixing(self.layer_norm(x, self.w.blocks[i].ln2), state, i, \n",
    "                    ffn.time_mix_k, ffn.time_mix_r, \n",
    "                    ffn.key.weight, ffn.value.weight, ffn.receptance.weight)\n",
    "            \n",
    "            x = self.w.head.weight @ self.layer_norm(x, self.w.ln_out)\n",
    "            return x.float(), state\n",
    "\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf027b6-7df9-4c0f-818e-013e7c49e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_logits(out, temperature=1.0, top_p=0.8):\n",
    "    probs = F.softmax(out, dim=-1).numpy()\n",
    "    sorted_probs = np.sort(probs)[::-1]\n",
    "    cumulative_probs = np.cumsum(sorted_probs)\n",
    "    cutoff = float(sorted_probs[np.argmax(cumulative_probs > top_p)])\n",
    "    probs[probs < cutoff] = 0\n",
    "    if temperature != 1.0:\n",
    "        probs = probs.pow(1.0 / temperature)\n",
    "    probs = probs / np.sum(probs)\n",
    "    out = np.random.choice(a=len(probs), p=probs)\n",
    "    return out\n",
    "\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "298dbbde-6535-406b-bd43-f2d886799f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using CPU. Loading /data1/ckw/RWKV-4-Pile-430M-20220808-8066 ...\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nUsing CPU. Loading {args.MODEL_NAME} ...')\n",
    "model = RWKV_RNN(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d366a89-02cb-4b5e-95ef-52f6376d3607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing context (slow version. see v2/rwkv/model.py for fast version)\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nPreprocessing context (slow version. see v2/rwkv/model.py for fast version)')\n",
    "init_state = None\n",
    "for token in tokenizer.encode(context).ids:\n",
    "    init_out, init_state = model.forward(token, init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5273e7a8-875e-4998-b98e-f81951a7af32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--[ Trial 0 ]----------------- \n",
      "DataWhalechina is an organization founded at Shanghai Jiao Tong University that helps learners learn artificial intelligence. Founded in 2015 by AI graduate student Yawei Li, DataWhalechina aims to help people learn to think more naturally about data. Learn more.\n",
      "\n",
      "50% of U.S. high school graduates who take data science courses go on to pursue masters degrees, which cost about $7,000, according to The American Council for an Energy Efficient Economy. Learn more.\n",
      "\n",
      "More than 600 startups compete for the same creative talent awards in 2016. If there is one award\n",
      "\n",
      "--[ Trial 1 ]----------------- \n",
      "DataWhalechina is an organization founded at Shanghai Jiao Tong University that helps learners learn artificial intelligence. Datawhalechina was established in 2013. The company was created to serve the needs of companies that seek to increase the utilization of machine learning technology in their environments. This aims to create a platform that will help increase the adoption of machine learning technology in organizations by creating better decision support tools.\n",
      "\n",
      "As of 2017, Datawhalechina's team of specialists are spread over the United States, Europe, Asia, Africa and Canada. Their strategy includes providing low-cost software solutions to the\n",
      "\n",
      "--[ Trial 2 ]----------------- \n",
      "DataWhalechina is an organization founded at Shanghai Jiao Tong University that helps learners learn artificial intelligence.\n",
      "The main objective of the organization is to provide diverse students with the information, skills, knowledge and ideas needed to tackle big challenges in their future. The success of the program has prompted the city government to give them more resources to bring more students in the program.\n",
      "\n",
      "Ethereum\n",
      "\n",
      "The Ethereum (ETH) blockchain, designed by XRP, is a decentralised ledger technology that enables Bitcoin (BTC) and other cryptocurrencies to be used as payment. It aims to be the largest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for TRIAL in range(NUM_TRIALS):\n",
    "    print(f'\\n\\n--[ Trial {TRIAL} ]-----------------', context, end=\"\")\n",
    "    all_tokens = []\n",
    "    out_last = 0\n",
    "    out, state = init_out.clone(), init_state.clone()\n",
    "    for i in range(LENGTH_PER_TRIAL):\n",
    "        token = sample_logits(out, TEMPERATURE, TOP_P)\n",
    "        all_tokens += [token]\n",
    "        tmp = tokenizer.decode(all_tokens[out_last:])\n",
    "        if '\\ufffd' not in tmp: # only print when we have a valid utf-8 string\n",
    "            print(tmp, end=\"\", flush=True)\n",
    "            out_last = i + 1\n",
    "        out, state = model.forward(token, state)       \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546bfd9-cf80-49bf-8c76-f3918d7d67e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
